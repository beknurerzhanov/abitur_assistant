import os
import shutil
import traceback
from pathlib import Path
from uuid import uuid4
from dotenv import load_dotenv

from fastapi import FastAPI, UploadFile, File, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import JSONResponse
from pydantic import BaseModel

from langchain_openai import OpenAI
from langchain.chains import ConversationalRetrievalChain
from langchain_chroma import Chroma

from chat_memory import memory, build_memory
from vectorstore import (
    get_embeddings,
    load_vectorstore_main,
    load_vectorstore_temp,
    clear_vectorstore_path
)
from ingest import process_single_file, load_all_documents
from prompt_template import PROMPT

# üîß –ù–∞—Å—Ç—Ä–æ–π–∫–∏
load_dotenv()
BASE_DIR = Path(__file__).parent.resolve()
DATA_DIR = (BASE_DIR / os.getenv("DATA_DIR", "data")).resolve()
INDEX_DIR = (BASE_DIR / os.getenv("INDEX_DIR", "indexes")).resolve()
MAIN_INDEX = INDEX_DIR / "main_index"
TEMP_INDEX = INDEX_DIR / "last_uploaded"

DATA_DIR.mkdir(parents=True, exist_ok=True)
MAIN_INDEX.mkdir(parents=True, exist_ok=True)
TEMP_INDEX.mkdir(parents=True, exist_ok=True)

# üß† –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è FastAPI
app = FastAPI()
app.add_middleware(
    CORSMiddleware,
    allow_origins=[os.getenv("FRONTEND_URL", "http://localhost:3000")],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# üìÑ –ú–æ–¥–µ–ª–∏ –¥–ª—è —á–∞—Ç–∞
class ChatHistoryPair(BaseModel):
    question: str
    answer: str

class ChatRequest(BaseModel):
    question: str
    history: list[ChatHistoryPair] = []

class ChatResponse(BaseModel):
    answer: str
    source_documents: list[dict]

# ü§ñ –ì–ª–æ–±–∞–ª—å–Ω—ã–π Chain
chain = None

@app.on_event("startup")
def startup_event():
    global chain
    try:
        texts, metadatas = load_all_documents(DATA_DIR)
        if not texts:
            print("‚ö†Ô∏è No documents found.")
            return

        vstore = Chroma.from_texts(
            texts, embedding=get_embeddings(), metadatas=metadatas,
            persist_directory=str(MAIN_INDEX)
        )

        retriever = vstore.as_retriever(search_kwargs={"k": 3})
        chain = ConversationalRetrievalChain.from_llm(
            llm=OpenAI(temperature=float(os.getenv("TEMPERATURE", 0.2))),
            retriever=retriever,
            memory=memory,
            return_source_documents=True,
            combine_docs_chain_kwargs={"prompt": PROMPT}
        )
        print("‚úÖ Chain initialized from existing documents.")
    except Exception as e:
        print("‚ùå Startup failed:")
        traceback.print_exc()

@app.post("/upload")
async def upload_file(file: UploadFile = File(...)):
    global chain, memory

    ext = Path(file.filename).suffix.lower()
    if ext not in [".pdf", ".docx", ".pptx", ".txt"]:
        return JSONResponse(status_code=400, content={"error": "–ù–µ–¥–æ–ø—É—Å—Ç–∏–º—ã–π —Ç–∏–ø —Ñ–∞–π–ª–∞"})

    filename = f"{uuid4().hex}{ext}"
    save_path = (DATA_DIR / filename).resolve()

    try:
        with save_path.open("wb") as buffer:
            shutil.copyfileobj(file.file, buffer)

        # ‚¨áÔ∏è –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Ñ–∞–π–ª –∏ –¥–æ–±–∞–≤–ª—è–µ–º –≤ —Ö—Ä–∞–Ω–∏–ª–∏—â–µ
        file_texts, file_meta = process_single_file(save_path)

        main_vstore = load_vectorstore_main()
        main_vstore.add_texts(file_texts, metadatas=file_meta)

        # ‚¨áÔ∏è –ø–µ—Ä–µ—Å–æ–±–∏—Ä–∞–µ–º chain —Å –Ω–æ–≤—ã–º —Ö—Ä–∞–Ω–∏–ª–∏—â–µ–º
        retriever = main_vstore.as_retriever(search_kwargs={"k": 3})
        memory = build_memory()
        chain = ConversationalRetrievalChain.from_llm(
            llm=OpenAI(temperature=float(os.getenv("TEMPERATURE", 0.2))),
            retriever=retriever,
            memory=memory,
            return_source_documents=True,
            combine_docs_chain_kwargs={"prompt": PROMPT}
        )

        # –í—Ä–µ–º–µ–Ω–Ω—ã–π chain ‚Äî —Ç–æ–ª—å–∫–æ –¥–ª—è –∞–≤—Ç–æ–æ—Ç–≤–µ—Ç–∞ –Ω–∞ –≤–æ–ø—Ä–æ—Å ¬´–æ —á—ë–º –¥–æ–∫—É–º–µ–Ω—Ç¬ª
        temp_chain = ConversationalRetrievalChain.from_llm(
            llm=OpenAI(temperature=float(os.getenv("TEMPERATURE", 0.2))),
            retriever=Chroma.from_texts(
                file_texts, embedding=get_embeddings(), metadatas=file_meta
            ).as_retriever(),
            memory=build_memory(),
            return_source_documents=True,
            combine_docs_chain_kwargs={"prompt": PROMPT}
        )

        auto_question = "–û —á—ë–º —ç—Ç–æ—Ç –¥–æ–∫—É–º–µ–Ω—Ç?"
        result = temp_chain.invoke({"question": auto_question, "chat_history": []})

        return {
            "message": f"‚úÖ –§–∞–π–ª '{file.filename}' –¥–æ–±–∞–≤–ª–µ–Ω.",
            "auto_question": auto_question,
            "auto_answer": result.get("answer", ""),
            "source_documents": [
                {"source": doc.metadata.get("source"), "chunk_id": doc.metadata.get("chunk_id")}
                for doc in result.get("source_documents", [])
            ]
        }

    except Exception as e:
        traceback.print_exc()
        return JSONResponse(status_code=500, content={"error": str(e)})


@app.post("/chat", response_model=ChatResponse)
def chat_endpoint(req: ChatRequest):
    global chain
    if not chain:
        raise HTTPException(500, "Chain not initialized")

    try:
        result = chain.invoke({
            "question": req.question.strip(),
            "chat_history": [(item.question, item.answer) for item in req.history]
        })

        answer = result.get("answer", "").strip()
        sources = [
            {"source": doc.metadata.get("source"), "chunk_id": doc.metadata.get("chunk_id")}
            for doc in result.get("source_documents", [])
        ]

        return ChatResponse(answer=answer, source_documents=sources)

    except Exception as e:
        traceback.print_exc()
        raise HTTPException(500, f"Internal error: {str(e)}")

@app.post("/clear")
def clear_chat():
    global chain, memory
    memory = build_memory()

    # üîπ –§–∞–π–ª—ã, –∫–æ—Ç–æ—Ä—ã–µ –ù–ï –Ω—É–∂–Ω–æ —É–¥–∞–ª—è—Ç—å
    base_files = {"doc.docx"}

    for file in DATA_DIR.glob("*"):
        if file.name not in base_files:
            try:
                file.unlink()
                print(f"üóëÔ∏è –£–¥–∞–ª—ë–Ω: {file.name}")
            except Exception as e:
                print(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å —É–¥–∞–ª–∏—Ç—å {file.name}: {e}")

    clear_vectorstore_path(MAIN_INDEX)
    clear_vectorstore_path(TEMP_INDEX)
    chain = None
    return {"message": "üßπ –ß–∞—Ç –æ—á–∏—â–µ–Ω. –ë–∞–∑–æ–≤—ã–µ —Ñ–∞–π–ª—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã."}

